<h2>Learning Nearest-Neighbor Quantizers from Labeled Data by Information Loss Minimization</h2>
<p><i><b>Svetlana Lazebnik, Maxim Raginsky</b></i>;
JMLR W&P 2:251-258, 2007.
<h3>Abstract</h3>

Markov Random Fields (MRFs) are used in a large array of computer vision and maching learning applications. Finding the Maximum Aposteriori (MAP) solution of an MRF is in general intractable, and one has to resort to approximate solutions, such as Belief Propagation, Graph Cuts, or more recently, approaches based on quadratic programming. We propose a novel type of approximation, Spectral relaxation to Quadratic Programming (SQP). We show our method offers tighter bounds than recently published work, while at the same time being computationally efficient. We compare our method to other algorithms on random MRFs in various settings.

