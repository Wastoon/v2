<h2>Learning a Nonlinear Embedding by Preserving Class Neighbourhood Structure</h2>
<p><i><b>Ruslan Salakhutdinov, Geoff Hinton</b></i>;
JMLR W&P 2:412-419, 2007.
<h3>Abstract</h3>

We show how to pretrain and fine-tune a multilayer neural network to learn a nonlinear transformation from the input space to a lowdimensional feature space in which K-nearest neighbour classification performs well. We also show how the non-linear transformation can be improved using unlabeled data. Our method achieves a much lower error rate than Support Vector Machines or standard backpropagation on a widely used version of the MNIST handwritten digit recognition task. If some of the dimensions of the low-dimensional feature space are not used for nearest neighbor classification, our method uses these dimensions to explicitly represent transformations of the digits that do not affect their identity.
