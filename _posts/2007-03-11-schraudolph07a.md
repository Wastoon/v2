---
title: A Stochastic Quasi-Newton Method for Online Convex Optimization
abstract: We develop stochastic variants of the well-known BFGS quasi-Newton optimization
  method, in both full and memory-limited (LBFGS) forms, for online optimization of
  convex functions. The resulting algorithm performs comparably to a well-tuned natural
  gradient descent but is scalable to very high-dimensional problems. On standard
  benchmarks in natural language processing, it asymptotically outperforms previous
  stochastic gradient methods for parameter estimation in conditional random fields.
  We are working on analyzing the convergence of online (L)BFGS, and extending it
  to nonconvex optimization problems.
pdf: "./schraudolph07a/schraudolph07a.pdf"
layout: inproceedings
id: schraudolph07a
month: 0
firstpage: 436
lastpage: 443
page: 436-443
origpdf: http://jmlr.org/proceedings/papers/v2/schraudolph07a/schraudolph07a.pdf
sections: 
author:
- given: Nicol N.
  family: Schraudolph
- given: Jin
  family: Yu
- given: Simon
  family: GÃ¼nter
date: '2007-03-11 00:07:16'
publisher: PMLR
---
