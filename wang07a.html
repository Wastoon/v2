<html>
<head>
<!--#include virtual="/css-scroll.txt"-->
</head>
<body>
<!--#include virtual="/nav-bar.txt"-->
</body> <head>
  <!--#include virtual="/css-scroll.txt"-->
<style>
. {font-family:verdana,helvetica,sans-serif}
a {text-decoration:none;color:#3030a0}
</style>
</head> 
<body>
<div id="content">
<h2>The Kernel Path in Kernelized LASSO</h2>
<p><i><b>Gang Wang, Dit-Yan Yeung, Frederick H. Lochovsky</b></i>;
JMLR W&P 2:580-587, 2007.
<h3>Abstract</h3>

Kernel methods implicitly map data points from the input space to some feature space where even relatively simple algorithms such as linear methods can deliver very impressive performance. Of crucial importance though is the choice of the kernel function, which determines the mapping between the input space and the feature space. The past few years have seen many efforts in learning either the kernel function or the kernel matrix. In this paper, we study the problem of learning the kernel hyperparameter in the context of the kernelized LASSO regression model. Specifically, we propose a solution path algorithm with respect to the hyperparameter of the kernel function. As the kernel hyperparameter changes its value, the solution path can be traced exactly without having to train the model multiple times. As a result, the optimal solution can be identified efficiently. Some simulation results will be presented to demonstrate the effectiveness of our proposed kernel path algorithm.

</div>
 <!--#include virtual="/nav-bar.txt"--> 
</body>
<p><center>Page last modified on Sat Oct 27 18:32:48 BST 2007.</center>
<body>
<p> 

<table width="100%"> <tr>
<td align="left"><font size="-1"><i><a
href="javascript:GoAddress('webmaster','jmlr.org');">webmaster<img
src=/images/atr.gif border=0>jmlr.org</a></i></font></td> <td
align="right"><font size="-1">Copyright &copy <a target="_top"
href="http://www.jmlr.org">JMLR</a> 2000.  All rights
reserved.</font></td> </tr> </table>
</body>